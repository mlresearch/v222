---
abstract: Most existing federated learning methods are unable to estimate model/predictive
  uncertainty since the client models are trained using the standard loss function
  minimization approach which ignores such uncertainties. In many situations, however,
  especially in limited data settings, it is beneficial to take into account the uncertainty
  in the model parameters at each client as it leads to more accurate predictions
  and also because reliable estimates of uncertainty can be used for tasks, such as
  out-of-distribution (OOD) detection, and sequential decision-making tasks, such
  as active learning. We present a framework for federated learning with uncertainty
  where, in each round, each client infers the posterior distribution over its parameters
  as well as the posterior predictive distribution (PPD), distills the PPD into a
  single deep neural network, and sends this network to the server. Unlike some of
  the recent Bayesian approaches to federated learning, our approach does not require
  sending the whole posterior distribution of the parameters from each client to the
  server but only the PPD in the distilled form as a deep neural network. In addition,
  when making predictions at test time, it does not require computationally expensive
  Monte-Carlo averaging over the posterior distribution because our approach always
  maintains the PPD in form a single deep neural network. Moreover, our approach does
  not make any restrictive assumptions, such as the form of the clientsâ€™ posterior
  distributions, or of their PPDs. We evaluate our approach on classification in federated
  setting, as well as active learning and OOD detection in federated settings, on
  which our approach outperforms various existing federated learning baselines.
section: Contributed Papers
title: Federated Learning with Uncertainty via Distilled Predictive Distributions
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bhatt24a
month: 0
tex_title: Federated Learning with Uncertainty via Distilled Predictive Distributions
firstpage: 153
lastpage: 168
page: 153-168
order: 153
cycles: false
bibtex_author: Bhatt, Shrey and Gupta, Aishwarya and Rai, Piyush
author:
- given: Shrey
  family: Bhatt
- given: Aishwarya
  family: Gupta
- given: Piyush
  family: Rai
date: 2024-02-27
address:
container-title: Proceedings of the 15th Asian Conference on Machine Learning
volume: '222'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 2
  - 27
pdf: https://proceedings.mlr.press/v222/bhatt24a/bhatt24a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v222/bhatt24a/bhatt24a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
