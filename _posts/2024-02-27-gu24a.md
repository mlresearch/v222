---
abstract: Recently, low-resource dialogue state tracking (DST) has received increasing
  attention. First obtaining state values then based on values to generate slot types
  has made great progress in this task. However, obtaining state values is still an
  under-studied problem. Existing extraction-based approaches cannot capture values
  that require the understanding of context and are not generalizable either. To address
  these issues, we propose a novel State VAlue Generation based framework (SVAG),
  decomposing DST into state value generation and domain slot generation. Specifically,
  we propose to generate state values and use self-training to further improve state
  value generation. Moreover, we design an estimator aiming at detecting incomplete
  generation and incorrect generation for pseudo-labeled data selection during self-training.
  Experimental results on the MultiWOZ 2.1 dataset show that our method which has
  only less than 1 billion parameters achieves state-of-the-art performance under
  the data ratio settings of 5%, 10%, and 25% when limited to models under 100 billion
  parameters. Compared to models with more than 100 billion parameters, SVAG still
  reaches competitive results.
section: Contributed Papers
title: State Value Generation with Prompt Learning and Self-Training for Low-Resource
  Dialogue State Tracking
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: gu24a
month: 0
tex_title: State Value Generation with Prompt Learning and Self-Training for Low-Resource
  Dialogue State Tracking
firstpage: 390
lastpage: 405
page: 390-405
order: 390
cycles: false
bibtex_author: Gu, Ming and Yang, Yan and Chen, Chengcai and Yu, Zhou
author:
- given: Ming
  family: Gu
- given: Yan
  family: Yang
- given: Chengcai
  family: Chen
- given: Zhou
  family: Yu
date: 2024-02-27
address:
container-title: Proceedings of the 15th Asian Conference on Machine Learning
volume: '222'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 2
  - 27
pdf: https://proceedings.mlr.press/v222/gu24a/gu24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
