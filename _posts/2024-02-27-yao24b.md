---
abstract: 'Spiking Neural Networks (SNNs) that operate in an event-driven manner and
  employ binary spike representation have recently emerged as promising candidates
  for energy-efficient computing. However, a cost bottleneck arises in obtaining high-performance
  SNNs: training a SNN model requires a large number of time steps in addition to
  the usual learning iterations, hence this limits their energy efficiency. This paper
  proposes a general training framework that enhances feature learning and activation
  efficiency within a limited time step, providing a new solution for more energy-efficient
  SNNs.  Our framework allows SNN neurons to learn robust spike feature from different
  receptive fields and update neuron states by utilizing both current stimuli and
  recurrence information transmitted from other neurons. This setting continuously
  complements information within a single time step. Additionally, we propose a projection
  function to merge these two stimuli to smoothly optimize neuron weights (spike firing
  threshold and activation). We evaluate the proposal for both convolution and recurrent
  models. Our experimental results indicate state-of-the-art visual classification
  tasks, including CIFAR10, CIFAR100, and TinyImageNet. Our framework achieves 72.41%
  and 72.31% top-1 accuracy with only 1 time step on CIFAR100 for CNNs and RNNs, respectively.
  Our method reduces 10X and 3X joule energy than a standard ANN and SNN, respectively,
  on CIFAR10, without additional time steps.'
section: Contributed Papers
title: Training a General Spiking Neural Network with Improved Efficiency and Minimum
  Latency
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yao24b
month: 0
tex_title: Training a General Spiking Neural Network with Improved Efficiency and
  Minimum Latency
firstpage: 1558
lastpage: 1573
page: 1558-1573
order: 1558
cycles: false
bibtex_author: Yao, Yunpeng and Wu, Man and Chen, Zheng and Zhang, Renyuan
author:
- given: Yunpeng
  family: Yao
- given: Man
  family: Wu
- given: Zheng
  family: Chen
- given: Renyuan
  family: Zhang
date: 2024-02-27
address:
container-title: Proceedings of the 15th Asian Conference on Machine Learning
volume: '222'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 2
  - 27
pdf: https://proceedings.mlr.press/v222/yao24b/yao24b.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v222/yao24b/yao24b-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
