---
abstract: Neural Networks (NN) are increasingly used for image classification in medical,
  transportation, and security devices. However, recent studies have revealed neural
  networks’ vulnerability against adversarial examples generated by adding small perturbations
  to images. These malicious samples are imperceptible by human eyes, but can give
  rise to misclassification by NN models. Defensive distillation is a defence mechanism
  in which the NN’s output probabilities are scaled to a user-defined range and used
  as labels to train a new model less sensitive to input perturbations. Despite initial
  success, defensive distillation was defeated by state-of-the-art attacks. A proposed
  countermeasure was to add noise in the inference time to hamper the adversarial
  attack which also decreased the model accuracy. In this paper, we address this limitation
  by proposing a two-phase training methodology to defend against adversarial attacks.
  In the first phase, we train architecturally diversified models individually using
  the cross-entropy loss function. In the second phase, we train the ensemble using
  a diversity-promoting loss function. Our experimental results show that our training
  methodology and noise addition in the inference time improved our ensemble’s resistance
  against adversarial attacks, while maintaining reasonable accuracy, compared to
  the state-of-the-art methods.
section: Contributed Papers
title: 'DENL: Diverse Ensemble and Noisy Logits for Improved Robustness of Neural
  Networks'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yazdani24a
month: 0
tex_title: "{DENL}: {D}iverse Ensemble and Noisy Logits for Improved Robustness of
  Neural Networks"
firstpage: 1574
lastpage: 1589
page: 1574-1589
order: 1574
cycles: false
bibtex_author: Yazdani, Mina and Karimi, Hamed and Samavi, Reza
author:
- given: Mina
  family: Yazdani
- given: Hamed
  family: Karimi
- given: Reza
  family: Samavi
date: 2024-02-27
address:
container-title: Proceedings of the 15th Asian Conference on Machine Learning
volume: '222'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 2
  - 27
pdf: https://proceedings.mlr.press/v222/yazdani24a/yazdani24a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v222/yazdani24a/yazdani24a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
