---
abstract: Deep learning-based recommendation systems (e.g., DLRMs) are widely used
  AI models to provide high-quality personalized recommendations. Training data used
  for modern recommendation systems commonly includes categorical features taking
  on tens-of-millions of possible distinct values. These categorical tokens are typically
  assigned learned vector representations, that are stored in large embedding tables,
  on the order of 100s of GB. Storing and accessing these tables represent a substantial
  performance burden. Our work proposes MEM-REC, a novel alternative representation
  approach for embedding tables. MEM-REC leverages Bloom filters and hashing methods
  to encode categorical features using two cache-friendly embedding tables. The first
  table (token embedding) contains raw embeddings (i.e. learned vector representation),
  and the second table (weight embedding), which is much smaller, contains weights
  to scale these raw embeddings to provide better discriminative capability to each
  data point. We provide a detailed architecture, design and analysis of MEM-REC addressing
  trade-offs in accuracy and computation requirements. In comparison with state-of-the-art
  techniques MEM-REC can not only maintain the recommendation quality and significantly
  reduce the memory footprint for commercial scale recommendation models but can also
  improve the embedding latency. In particular, based on our results, MEM-REC compresses
  the MLPerf CriteoTB benchmark DLRM model size by $2900\times$ and performs up to
  $3.4\times$ faster embeddings while achieving the same AUC as that of the full uncompressed
  model.
section: Contributed Papers
title: 'Mem-Rec: Memory Efficient Recommendation System using Alternative Representation'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jha24a
month: 0
tex_title: "{Mem-Rec}: {M}emory Efficient Recommendation System using Alternative
  Representation"
firstpage: 518
lastpage: 533
page: 518-533
order: 518
cycles: false
bibtex_author: Jha, Gopi Krishna and Thomas, Anthony and Jain, Nilesh and Gobriel,
  Sameh and Rosing, Tajana and Iyer, Ravi
author:
- given: Gopi Krishna
  family: Jha
- given: Anthony
  family: Thomas
- given: Nilesh
  family: Jain
- given: Sameh
  family: Gobriel
- given: Tajana
  family: Rosing
- given: Ravi
  family: Iyer
date: 2024-02-27
address:
container-title: Proceedings of the 15th Asian Conference on Machine Learning
volume: '222'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 2
  - 27
pdf: https://proceedings.mlr.press/v222/jha24a/jha24a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v222/jha24a/jha24a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
