---
abstract: It is essential for models to gradually adapt to the worldâ€™s increasing
  complexity, and we can use models more effectively if they keep up with the times.
  However, the technique of continuous learning (CL) has an issue with catastrophic
  forgetting, and effective continuous learning methods can only be attained by effectively
  limiting forgetting and learning new tasks. In this study, we offer the Classifier
  Expander(CE) method, which combines the regularization-based and replay-based approaches.
  By undergoing two stages of training, it fulfills the aforementioned standards.
  The training content for the new task is limited to the portion of the network relevant
  to that task in the first stage, which uses the replay approach to reduce the forgetting
  problem. This strategy minimizes disruption to the old task while facilitating efficient
  learning of the new one. Utilizing all of the data available, the second stage retrains
  the network and sufficiently trains the classifier to balance the learning performance
  of the old and new tasks. Our method regularly outperforms previous CL methods on
  the CIFAR-100 and CUB-200 datasets, obtaining an average improvement of 2.94% on
  the class-incremental learning and 1.16% on the task-incremental learning compared
  to the best method currently available. Our code is available at https://github.com/EmbraceTomorrow/CE.
section: Contributed Papers
title: Overcoming catastrophic forgetting with classifier expander
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu24b
month: 0
tex_title: Overcoming catastrophic forgetting with classifier expander
firstpage: 803
lastpage: 817
page: 803-817
order: 803
cycles: false
bibtex_author: Liu, Xinchen and Wang, Hongbo and Tian, Yingjian and Xie, Linyao
author:
- given: Xinchen
  family: Liu
- given: Hongbo
  family: Wang
- given: Yingjian
  family: Tian
- given: Linyao
  family: Xie
date: 2024-02-27
address:
container-title: Proceedings of the 15th Asian Conference on Machine Learning
volume: '222'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 2
  - 27
pdf: https://proceedings.mlr.press/v222/liu24b/liu24b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
