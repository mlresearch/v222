---
abstract: Convolutional neural networks (CNNs) are becoming deeper and wider to achieve
  higher accuracy and lower loss, significantly expanding the computational resources.
  Especially, training CNN models extensively consumes memory mainly due to storing
  intermediate feature maps generated in the forward-propagation for calculating the
  gradient in the backpropagation. The memory usage of the CNN model training escalates
  with the increase in batch size and the complexity of the model. Therefore, a lightweight
  training method is essential, especially when the computational resources are limited.
  In this paper, we propose a CNN training mechanism called Facto-CNN, leveraging
  low-rank tensor factorization and lossy tensor compression to reduce the memory
  usage required in training the CNN models. Facto-CNN factorizes the weight tensors
  of convolutional and fully-connected layers and then only updates one of the factorized
  tensors for each layer, dramatically reducing the feature map size stored in the
  memory. To further reduce memory consumption, Facto-CNN compresses the feature maps
  with a simple lossy compression technique that exploits the value similarity in
  the feature maps. Our experimental evaluation demonstrates that Facto-CNN reduces
  the memory usage for storing the feature maps by 68-93% with a trivial accuracy
  degradation when training the CNN models.
section: Contributed Papers
title: 'Facto-CNN: Memory-Efficient CNN Training with Low-rank Tensor Factorization
  and Lossy Tensor Compression'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lee24b
month: 0
tex_title: "{Facto-CNN}: {M}emory-Efficient {CNN} Training with Low-rank Tensor Factorization
  and Lossy Tensor Compression"
firstpage: 662
lastpage: 677
page: 662-677
order: 662
cycles: false
bibtex_author: Lee, Seungtae and Ko, Jonghwan and Hong, Seokin
author:
- given: Seungtae
  family: Lee
- given: Jonghwan
  family: Ko
- given: Seokin
  family: Hong
date: 2024-02-27
address:
container-title: Proceedings of the 15th Asian Conference on Machine Learning
volume: '222'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 2
  - 27
pdf: https://proceedings.mlr.press/v222/lee24b/lee24b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
