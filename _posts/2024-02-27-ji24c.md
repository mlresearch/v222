---
abstract: 'Generalized zero-shot learning (GZSL) is still a technical challenge of
  deep learning. To preserve the semantic relation between source and target classes
  when only trained with data from source classes, we address the quantification of
  the knowledge transfer from an information-theoretic viewpoint. We use the prototypical
  model and format the variables of concern as a probability vector. Taking advantage
  of the probability vector representation, information measurements can be effectively
  evaluated with simple closed forms. We propose two information-theoretic loss functions:
  a mutual information loss to bridge seen data and target classes; an uncertainty-aware
  entropy constraint loss to prevent overfitting when using seen data to learn the
  embedding of target classes. Simulation shows that, as a deterministic model, our
  proposed method obtains state-of-the-art results on GZSL benchmark datasets. We
  achieve 21% − 64% improvements over the baseline model – deep calibration network
  (DCN) and demonstrate that a deterministic model can perform as well as generative
  ones. Furthermore, the proposed method is compatible with generative models and
  can noticeably improve their performance.'
section: Contributed Papers
title: Prototypical Model with Information-Theoretic Loss Functions for Generalized
  Zero-Shot Learning
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ji24c
month: 0
tex_title: Prototypical Model with Information-Theoretic Loss Functions for Generalized
  Zero-Shot Learning
firstpage: 566
lastpage: 581
page: 566-581
order: 566
cycles: false
bibtex_author: Ji, Chunlin and Xiong, Zhan and Zhang, Meiying and Yang, Huiwen and
  Chen, Feng and Shen, Hanchun
author:
- given: Chunlin
  family: Ji
- given: Zhan
  family: Xiong
- given: Meiying
  family: Zhang
- given: Huiwen
  family: Yang
- given: Feng
  family: Chen
- given: Hanchun
  family: Shen
date: 2024-02-27
address:
container-title: Proceedings of the 15th Asian Conference on Machine Learning
volume: '222'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 2
  - 27
pdf: https://proceedings.mlr.press/v222/ji24c/ji24c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
