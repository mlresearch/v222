---
abstract: Modern DNN-based recommendation systems rely on training-derived embeddings
  of sparse features. Input sparsity makes obtaining high-quality embeddings for rarely-occurring
  categories harder as their representations are updated infrequently. We demonstrate
  a training-time technique to produce superior embeddings via effective cross-category
  learning and theoretically explain its surprising effectiveness. The scheme, termed
  the multi-layer embeddings training (MLET), trains embeddings using factorization
  of the embedding layer, with an inner dimension higher than the target embedding
  dimension. For inference efficiency, MLET converts the trained two-layer embedding
  into a single-layer one thus keeping inference-time model size unchanged. Empirical
  superiority of MLET is puzzling as its search space is not larger than that of the
  single-layer embedding. The strong dependence of MLET on the inner dimension is
  even more surprising. We develop a theory that explains both of these behaviors
  by showing that MLET creates an adaptive update mechanism modulated by the singular
  vectors of embeddings. When tested on multiple state-of-the-art recommendation models
  for click-through rate (CTR) prediction tasks, MLET consistently produces better
  models, especially for rare items. At constant model quality, MLET allows embedding
  dimension, and model size, reduction by up to 16x, and 5.8x on average, across the
  models.
section: Contributed Papers
title: Enhancing Cross-Category Learning in Recommendation Systems with Multi-Layer
  Embedding Training
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: deng24a
month: 0
tex_title: Enhancing Cross-Category Learning in Recommendation Systems with Multi-Layer
  Embedding Training
firstpage: 263
lastpage: 278
page: 263-278
order: 263
cycles: false
bibtex_author: Deng, Zihao and Ghaemmaghami, Benjamin and Singh, Ashish Kumar and
  Cho, Benjamin and Orshansky, Leo and Erez, Mattan and Orshansky, Michael
author:
- given: Zihao
  family: Deng
- given: Benjamin
  family: Ghaemmaghami
- given: Ashish Kumar
  family: Singh
- given: Benjamin
  family: Cho
- given: Leo
  family: Orshansky
- given: Mattan
  family: Erez
- given: Michael
  family: Orshansky
date: 2024-02-27
address:
container-title: Proceedings of the 15th Asian Conference on Machine Learning
volume: '222'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 2
  - 27
pdf: https://proceedings.mlr.press/v222/deng24a/deng24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
