---
abstract: Diffusion models are generative models that have shown significant advantages
  compared to other generative models in terms of higher generation quality and more
  stable training. However, the computational need for training diffusion models is
  considerably increased. In this work, we incorporate prototype learning into diffusion
  models to achieve high generation quality faster than the original diffusion model.
  Instead of randomly initialized class embeddings, we use separately learned class
  prototypes as the conditioning information to guide the diffusion process. We observe
  that our method, called ProtoDiffusion, achieves better performance in the early
  stages of training compared to the baseline method, signifying that using the learned
  prototypes shortens the training time. We demonstrate the performance of ProtoDiffusion
  using various datasets and experimental settings, achieving the best performance
  in shorter times across all settings.
section: Contributed Papers
title: 'ProtoDiffusion: Classifier-Free Diffusion Guidance with Prototype Learning'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: baykal24a
month: 0
tex_title: "{ProtoDiffusion}: {C}lassifier-Free Diffusion Guidance with Prototype
  Learning"
firstpage: 106
lastpage: 120
page: 106-120
order: 106
cycles: false
bibtex_author: Baykal, Gulcin and Karagoz, Halil Faruk and Binhuraib, Taha and Unal,
  Gozde
author:
- given: Gulcin
  family: Baykal
- given: Halil Faruk
  family: Karagoz
- given: Taha
  family: Binhuraib
- given: Gozde
  family: Unal
date: 2024-02-27
address:
container-title: Proceedings of the 15th Asian Conference on Machine Learning
volume: '222'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 2
  - 27
pdf: https://proceedings.mlr.press/v222/baykal24a/baykal24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
