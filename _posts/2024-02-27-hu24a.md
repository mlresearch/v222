---
abstract: Supervised learning models are challenged by the intrinsic complexities
  of training data such as outliers and minority subpopulations and intentional attacks
  at inference time with adversarial samples. While traditional robust learning methods
  and the recent adversarial training approaches are designed to handle each of the
  two challenges, to date, no work has been done to develop models that are robust
  with regard to the low-quality training data and the potential adversarial attack
  at inference time simultaneously. It is for this reason that we introduce \underline{O}utlier
  \underline{R}obust \underline{A}dversarial \underline{T}raining (ORAT) in this work.
  ORAT is based on a bi-level optimization formulation of adversarial training with
  a robust rank-based loss function. Theoretically, we show that the learning objective
  of ORAT satisfies the $\mathcal{H}$-consistency in binary classification, which
  establishes it as a proper surrogate to adversarial 0/1 loss. Furthermore, we analyze
  its generalization ability and provide uniform convergence rates in high probability.
  ORAT can be optimized with a simple algorithm. Experimental evaluations on three
  benchmark datasets demonstrate the effectiveness and robustness of ORAT in handling
  outliers and adversarial attacks. Our code is available at \url{https://github.com/discovershu/ORAT}.
section: Contributed Papers
title: Outlier Robust Adversarial Training
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hu24a
month: 0
tex_title: Outlier Robust Adversarial Training
firstpage: 454
lastpage: 469
page: 454-469
order: 454
cycles: false
bibtex_author: Hu, Shu and Yang, Zhenhuan and Wang, Xin and Ying, Yiming and Lyu,
  Siwei
author:
- given: Shu
  family: Hu
- given: Zhenhuan
  family: Yang
- given: Xin
  family: Wang
- given: Yiming
  family: Ying
- given: Siwei
  family: Lyu
date: 2024-02-27
address:
container-title: Proceedings of the 15th Asian Conference on Machine Learning
volume: '222'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 2
  - 27
pdf: https://proceedings.mlr.press/v222/hu24a/hu24a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v222/hu24a/hu24a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
